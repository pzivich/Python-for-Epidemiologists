{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Maximum Likelihood Estimator\n",
    "The targeted maximum likelihood estimator (TMLE) is a doubly robust estimator. What distinguishes it from other doubly robust estimators (augmented-IPTW) is that it uses a secondary targeting (hence the name) step that optimizes the bias-variance tradeoff for the target parameter. A common target parameter is the sample average treatment effect, which compares to counterfactual where all individuals in the study sample were treated versus the counterfactual where no individual was treated. Throughout this section, I will use the notation that is common in the TMLE literature. This is a little different from the notation in other documents.\n",
    "\n",
    "The target parameter is defined as\n",
    "$$\\psi = E_L\\left[E\\left[Y^{a=1}|L\\right] - E\\left[Y^{a=0}|L\\right]\\right]$$\n",
    "We will focus on this parameter, but other estimates (like risk ratio and odds ratio) are also implemented\n",
    "\n",
    "This tutorial focuses on estimating TMLE with missing outcome data. I will demonstrate with both the default regression models and machine learning algorithms.\n",
    "\n",
    "## Missing Outcome Data\n",
    "To motivate our example, we will use a simulated data set included with *zEpid*. In the data set, we have a cohort of HIV-positive individuals. We are interested in the sample average treatment effect of antiretroviral therapy (ART) on all-cause mortality at 45-weeks. Based on substantive background knowledge, we believe that the treated and untreated population are exchangeable based gender, age, CD4 T-cell count, and detectable viral load. \n",
    "\n",
    "While we conducted a complete-case analysis in the previous tutorial, TMLE can also natively handle missing outcome data. This is accomplished by using inverse probability of missing weights in the background. We can add this model by specifying the `missing_model()` function. \n",
    "\n",
    "To start, we will load our data and create some spline terms for age and CD4 T-cell count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 547 entries, 0 to 546\n",
      "Data columns (total 12 columns):\n",
      "id         547 non-null int64\n",
      "male       547 non-null int64\n",
      "age0       547 non-null int64\n",
      "cd40       547 non-null int64\n",
      "dvl0       547 non-null int64\n",
      "art        547 non-null int64\n",
      "dead       517 non-null float64\n",
      "t          547 non-null float64\n",
      "age_rs1    547 non-null float64\n",
      "age_rs2    547 non-null float64\n",
      "cd4_rs1    547 non-null float64\n",
      "cd4_rs2    547 non-null float64\n",
      "dtypes: float64(6), int64(6)\n",
      "memory usage: 55.6 KB\n"
     ]
    }
   ],
   "source": [
    "from zepid import load_sample_data, spline\n",
    "from zepid.causal.doublyrobust import TMLE\n",
    "\n",
    "df = load_sample_data(False)\n",
    "df[['age_rs1', 'age_rs2']] = spline(df, 'age0', n_knots=3, term=2, restricted=True)\n",
    "df[['cd4_rs1', 'cd4_rs2']] = spline(df, 'cd40', n_knots=3, term=2, restricted=True)\n",
    "\n",
    "dfcc = df.drop(columns=['cd4_wk45'])\n",
    "dfcc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To accomodate missing outcome data, we proceed the previous process from the prior tutorial. However, this time we will also specify the `missing_model()` function. This model allows us to generate inverse probability of missing weights (IPMW) for the outcome. These weights are used to update the IPTW and the targeting process. Essentially, this procedure allows us to go from a missing completely at random assumption to the weaker assumption of missing at random. See Gruber, S., & van der Laan, M. J. (2011). tmle: An R package for targeted maximum likelihood estimation. for details on the procedure\n",
    "\n",
    "To estimate TMLE using a parametric procedure, you can use the below code. In this example, we assume that outcome data is missing dependent on treatment (ART), gender, age, detected viral load, and CD4 T-cell count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                Targeted Maximum Likelihood Estimator                 \n",
      "======================================================================\n",
      "Risk Difference:  -0.08\n",
      "95.0% two-sided CI: (-0.153 , -0.008)\n",
      "----------------------------------------------------------------------\n",
      "Risk Ratio:  0.562\n",
      "95.0% two-sided CI: (0.294 , 1.072)\n",
      "----------------------------------------------------------------------\n",
      "Odds Ratio:  0.512\n",
      "95.0% two-sided CI: (0.247 , 1.058)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "tml = TMLE(dfcc, exposure='art', outcome='dead')\n",
    "tml.exposure_model('male + age0 + cd40 + cd4_rs1 + cd4_rs2 + dvl0', print_results=False)\n",
    "tml.missing_model('art + male + age0 + cd40 + cd4_rs1 + cd4_rs2 + dvl0', print_results=False)\n",
    "tml.outcome_model('art + male + age0 + cd40 + cd4_rs1 + cd4_rs2 + dvl0', print_results=False)\n",
    "tml.fit()\n",
    "tml.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking back at the previous TMLE tutorial, our results are fairly consistent. \n",
    "\n",
    "## Maching Learning\n",
    "As in the previous tutorial, we can also use machine learning to estimate the predicted values. Again, we will use super learner with neural network, naive Bayes, L1-penalized logistic regression, L2- penalized logistic regression, AdaBoost, and random forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                Targeted Maximum Likelihood Estimator                 \n",
      "======================================================================\n",
      "Risk Difference:  -0.08\n",
      "95.0% two-sided CI: (-0.15 , -0.009)\n",
      "----------------------------------------------------------------------\n",
      "Risk Ratio:  0.561\n",
      "95.0% two-sided CI: (0.299 , 1.055)\n",
      "----------------------------------------------------------------------\n",
      "Odds Ratio:  0.512\n",
      "95.0% two-sided CI: (0.252 , 1.04)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import supylearner\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initializing the ML algorithms\n",
    "neural = MLPClassifier(hidden_layer_sizes=(8,), random_state=1463)\n",
    "log1 = LogisticRegression(penalty='l1', random_state=201)\n",
    "log2 = LogisticRegression(penalty='l2', random_state=103)\n",
    "randf = RandomForestClassifier(random_state=141)\n",
    "adaboost = AdaBoostClassifier(random_state=505)\n",
    "bayes = GaussianNB()\n",
    "\n",
    "# Initializing SuPyLearner with the above algorithms\n",
    "lib = [neural, log1, log2, randf, adaboost, bayes]\n",
    "libnames = [\"Neural-Net\", \"Log_L1\", \"Log_L2\", \"Random Forest\", \"AdaBoost\", \"Bayes\"]\n",
    "sl = supylearner.SuperLearner(lib, libnames, loss=\"nloglik\", K=10, print_results=False)\n",
    "\n",
    "# Estimating TMLE with ML algorithms\n",
    "tmle = TMLE(dfcc, exposure='art', outcome='dead')  # Step 1) Initialize TMLE class\n",
    "tmle.exposure_model('male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0',\n",
    "                    custom_model=sl, print_results=False)  # Step 2) Specify exposure model\n",
    "tmle.missing_model('art + male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0',\n",
    "                    custom_model=sl, print_results=False)  # Step 3) Specify exposure model\n",
    "tmle.outcome_model('art + male + age0 + age_rs1 + age_rs2 + cd40 + cd4_rs1 + cd4_rs2 + dvl0',\n",
    "                   custom_model=sl, print_results=False)  # Step 4) Specify outcome model\n",
    "tmle.fit()  # Step 5) Targeting step\n",
    "tmle.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we obtained similar results between the parametric TMLE and TMLE with super learner\n",
    "\n",
    "# Conclusion\n",
    "In this tutorial, I have described how TMLE can be estimated with missing outcome data and how to do so with *zEpid*. `TMLE` can be used to estimate missing data for binary or continuous outcomes. Please refer to other tutorials for more options and specifications available with `TMLE`.\n",
    "\n",
    "## References\n",
    "\n",
    "Schuler, Megan S., and Sherri Rose. \"Targeted maximum likelihood estimation for causal inference in observational studies.\" American Journal of Epidemiology 185.1 (2017): 65-73.\n",
    "\n",
    "van der Laan, Mark J., and Sherri Rose. Targeted learning: causal inference for observational and experimental data. Springer Science & Business Media, 2011.\n",
    "\n",
    "van Der Laan, Mark J., and Daniel Rubin. \"Targeted maximum likelihood learning.\" The International Journal of Biostatistics 2.1 (2006).\n",
    "\n",
    "Gruber, S., & van der Laan, M. J. (2011). tmle: An R package for targeted maximum likelihood estimation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
