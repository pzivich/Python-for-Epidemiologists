{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizability\n",
    "First, we will approach to problem of generalizability. To frame our problem, imagine we took a random sample from our target population. We collected some basic data from everyone in the random sample. We then recruited individuals to take part in a trial we were conducting. Of the 3,000 individuals included in our study, 486 participated in our trial. However, the trial participants were not a random sample of our target population. Therefore, we are worried about generalizing our results from the trial participants to our target population.\n",
    "\n",
    "## Randomized Control Trial\n",
    "For simplicity, we will first generalize our results from a randomized trial (we will not need to worry about confounding). There are three options for generalizing results in *zEpid*; inverse probability of sampling weights (`IPSW`), g-transport formula (`GTransportFormula`), and doubly robust estimator (`AIPSW`).\n",
    "\n",
    "Before we start generalizing our results, let's take a look at the data and estimate the sample average treatment effect ($SATE$). The $SATE$ is defined as\n",
    "$$SATE = E[Y^{a=1}] - E[Y^{a=0}]$$\n",
    "Our sample is indicated by `S=1` and includes only 486 individuals. We are interested in the causal effect of $A$ on $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 7 columns):\n",
      "id      3000 non-null int64\n",
      "Y       486 non-null float64\n",
      "A       486 non-null float64\n",
      "S       3000 non-null int64\n",
      "L       3000 non-null int64\n",
      "W       3000 non-null float64\n",
      "W_sq    3000 non-null float64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 164.1 KB\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zepid import RiskDifference\n",
    "from zepid import load_generalize_data\n",
    "\n",
    "df = load_generalize_data(False)\n",
    "df['W_sq'] = df['W']**2\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison:0 to 1.0\n",
      "+-----+-------+-------+\n",
      "|     |   D=1 |   D=0 |\n",
      "+=====+=======+=======+\n",
      "| E=1 |    84 |   172 |\n",
      "+-----+-------+-------+\n",
      "| E=0 |    51 |   179 |\n",
      "+-----+-------+-------+ \n",
      "\n",
      "======================================================================\n",
      "                            Risk Ratio                                \n",
      "======================================================================\n",
      "        Risk  SD(Risk)  Risk_LCL  Risk_UCL\n",
      "Ref:0  0.222     0.027     0.168     0.275\n",
      "1.0    0.328     0.029     0.271     0.386\n",
      "----------------------------------------------------------------------\n",
      "       RiskDifference  SD(RD)  RD_LCL  RD_UCL\n",
      "Ref:0           0.000     NaN     NaN     NaN\n",
      "1.0             0.106    0.04   0.028   0.185\n",
      "----------------------------------------------------------------------\n",
      "       RiskDifference    CLD  LowerBound  UpperBound\n",
      "Ref:0           0.000    NaN         NaN         NaN\n",
      "1.0             0.106  0.157      -0.672       0.328\n",
      "----------------------------------------------------------------------\n",
      "Missing E:    0\n",
      "Missing D:    0\n",
      "Missing E&D:  0\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "dfs = df.loc[df['S'] == 1].copy()\n",
    "\n",
    "rd = RiskDifference()\n",
    "rd.fit(dfs, exposure='A', outcome='Y')\n",
    "rd.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the treatment effect of $A$ on $Y$ was 0.11 (95% CL: 0.028, 0.185) in the trial. However, we are concerned about the generalizability of our trial results to our target population. Specifically, we are worried about the individuals who enrolled into our study no longer being representative of the target. We believe $L$ and $W$ are modifiers and have different distributions between the trial population and the target population. Let's compare three methods to deal with this approach\n",
    "\n",
    "### IPSW\n",
    "Inverse Probability of Sampling Weights (IPSW) are an approach to reweight the study sample to reflect the full population. Similar to other inverse probability weighting approaches, we generate weights to create a pseudo-population that is reflective of the population we want to draw inference regarding.\n",
    "\n",
    "IPSW are sampling weights, which weight the observed sample to be reflective of the target population. For generating these weights, factors that (1) differ between the sample and the target and (2) are modifiers should be included in this model. Remember that if something has an effect on the outcome, *it must be a modifier on at least one scale* (risk difference / risk ratio). Therefore, it would be prudent to include strong causes of the outcome that differ substantially between the sample and target.\n",
    "\n",
    "In our example, we assume that `L` and `W` are sufficient for our results to generalize from the sample to the target population. Below is code to estimate the target population risk difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "           Inverse Probability of Sampling Weights\n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.0542\n",
      "Risk Ratio:       1.1665\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from zepid.causal.generalize import IPSW\n",
    "\n",
    "ipsw = IPSW(df, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "ipsw.regression_models('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "ipsw.fit()\n",
    "ipsw.summary()\n",
    "\n",
    "rd = ipsw.risk_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals come from a boostrapping procedure. This bootstrapping procedure is different from other estimators. Instead of resampling from our entire study sample, we need to account for random error in selection of the study sample and random error in the selection of the basic data collection. To do this, we divide our data into the two pieces, sample from them independently, then stack them again. We then estimate the risk difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% LCL: -0.044\n",
      "95% UCL: 0.152\n"
     ]
    }
   ],
   "source": [
    "# Step 1: divide data\n",
    "dfss = df.loc[df['S'] == 1].copy()\n",
    "dftp = df.loc[df['S'] == 0].copy()\n",
    "rd_bs = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Step 2: Resample data\n",
    "    dfs = dfss.sample(n=dfss.shape[0], replace=True)\n",
    "    dft = dftp.sample(n=dftp.shape[0], replace=True)\n",
    "\n",
    "    # Step 3: restack the data\n",
    "    dfb = pd.concat([dfs, dft])\n",
    "\n",
    "    # Step 4: Estimate IPSW\n",
    "    ipsw = IPSW(dfb, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "    ipsw.regression_models('L + W + L:W', print_results=False)\n",
    "    ipsw.fit()\n",
    "\n",
    "    rd_bs.append(ipsw.risk_difference)\n",
    "\n",
    "se = np.std(rd_bs, ddof=1)\n",
    "\n",
    "print('95% LCL:', np.round(rd - 1.96*se, 3))\n",
    "print('95% UCL:', np.round(rd + 1.96*se, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the probability of `Y` given everyone in the target population had `A=1` would have been 5 percentage points higher (95% CL: -0.04, 0.15) than if everyone in the target population had `A=0`. Note that this conclusion is different than our $SATE$\n",
    "\n",
    "### G-transport Formula\n",
    "Alternatively, we can also use the g-formula to estimate the causal effect in our target population. Instead of weighting our population, we will estimate a model (including the modifiers) for our trial participants. Then we will use the fitted parametric model to predict the counterfactual outcomes in both the study sample and the target population sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                       g-Transport formula\n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.0567\n",
      "Risk Ratio:       1.1806\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from zepid.causal.generalize import GTransportFormula\n",
    "\n",
    "gtf = GTransportFormula(df, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "gtf.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "gtf.fit()\n",
    "gtf.summary()\n",
    "\n",
    "rd = gtf.risk_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we use a bootstrapping procedure for confidence intervals. The same procedure as previously described is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% LCL: -0.048\n",
      "95% UCL: 0.161\n"
     ]
    }
   ],
   "source": [
    "# Step 1: divide data\n",
    "dfss = df.loc[df['S'] == 1].copy()\n",
    "dftp = df.loc[df['S'] == 0].copy()\n",
    "rd_bs = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Step 2: Resample data\n",
    "    dfs = dfss.sample(n=dfss.shape[0], replace=True)\n",
    "    dft = dftp.sample(n=dftp.shape[0], replace=True)\n",
    "\n",
    "    # Step 3: restack the data\n",
    "    dfb = pd.concat([dfs, dft])\n",
    "\n",
    "    # Step 4: Estimate IPSW\n",
    "    gtf = GTransportFormula(dfb, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "    gtf.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "    gtf.fit()\n",
    "\n",
    "    rd_bs.append(gtf.risk_difference)\n",
    "\n",
    "se = np.std(rd_bs, ddof=1)\n",
    "print('95% LCL:', np.round(rd - 1.96 * se, 3))\n",
    "print('95% UCL:', np.round(rd + 1.96 * se, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the probability of `Y` given everyone in the target population had `A=1` would have been 6 percentage points higher (95% CL: -0.05, 0.16) than if everyone in the target population had `A=0`. Note that this conclusion is different than our $SATE$, but similar to IPSW.\n",
    "\n",
    "### Augmented-IPSW\n",
    "Similarly to causal inference in an observational study, we may be concerned regarding model misspecification. Through AIPSW, we have 'two chances' to get our model specified correctly. Essentially, it is a recipe to merge IPSW and the g-transport formula together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "           Augmented Inverse Probability of Sampling Weights          \n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.055\n",
      "Risk Ratio:       1.1738\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from zepid.causal.generalize import AIPSW\n",
    "\n",
    "aipw = AIPSW(df, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "aipw.weight_model('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "aipw.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "aipw.fit()\n",
    "aipw.summary()\n",
    "\n",
    "rd = aipw.risk_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use a bootstrapping procedure to obtain our confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% LCL: -0.054\n",
      "95% UCL: 0.164\n"
     ]
    }
   ],
   "source": [
    "# Step 1: divide data\n",
    "dfss = df.loc[df['S'] == 1].copy()\n",
    "dftp = df.loc[df['S'] == 0].copy()\n",
    "rd_bs = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Step 2: Resample data\n",
    "    dfs = dfss.sample(n=dfss.shape[0], replace=True)\n",
    "    dft = dftp.sample(n=dftp.shape[0], replace=True)\n",
    "\n",
    "    # Step 3: restack the data\n",
    "    dfb = pd.concat([dfs, dft])\n",
    "\n",
    "    # Step 4: Estimate IPSW\n",
    "    aipw = AIPSW(dfb, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "    aipw.weight_model('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "    aipw.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "    aipw.fit()\n",
    "\n",
    "    rd_bs.append(aipw.risk_difference)\n",
    "\n",
    "se = np.std(rd_bs, ddof=1)\n",
    "print('95% LCL:', np.round(rd - 1.96 * se, 3))\n",
    "print('95% UCL:', np.round(rd + 1.96 * se, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the probability of `Y` given everyone in the target population had `A=1` would have been 6 percentage points higher (95% CL: -0.05, 0.16) than if everyone in the target population had `A=0`. Note that this conclusion is different than our $SATE$, but similar to both IPSW and g-transport. \n",
    "\n",
    "## Observational Study\n",
    "In the previous examples, we assumed $Y^a \\amalg A$. Let's generalize to observational studies with confounders, i.e. $Y^a \\amalg A | L$. For observational studies, we will need to make some minor tweaks to our previous estimation procedures. In the following, we will assume that `L` and `W` are both potential confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 7 columns):\n",
      "id      3000 non-null int64\n",
      "Y       486 non-null float64\n",
      "A       486 non-null float64\n",
      "S       3000 non-null int64\n",
      "L       3000 non-null int64\n",
      "W       3000 non-null float64\n",
      "W_sq    3000 non-null float64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 164.1 KB\n"
     ]
    }
   ],
   "source": [
    "from zepid.causal.ipw import IPTW\n",
    "\n",
    "df = load_generalize_data(True)\n",
    "df['W_sq'] = df['W']**2\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPSW\n",
    "For IPSW to account for confounding, IPTW must be generated and passed to `IPSW`. First we will calculate the inverse probability of treatment weights with `IPTW`. Then we will specify the optional `weights` argument for `IPSW`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPTW estimation\n",
    "iptw = IPTW(df, treatment='A', stabilized=True)\n",
    "iptw.regression_models('L + W + W_sq', print_results=False)\n",
    "iptw.fit()\n",
    "\n",
    "df['iptw'] = iptw.Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "           Inverse Probability of Sampling Weights\n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.0177\n",
      "Risk Ratio:       1.0504\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "ipsw = IPSW(df, exposure='A', outcome='Y', selection='S', generalize=True, weights='iptw')\n",
    "ipsw.regression_models('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "ipsw.fit()\n",
    "ipsw.summary()\n",
    "\n",
    "rd = ipsw.risk_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the probability of `Y` given everyone in the target population had `A=1` would have been 5 percentage points higher than if everyone in the target population had `A=0`. As we would hope (since I simulated the data, I know the true answer), our results are similar to the true value.\n",
    "\n",
    "Confidence intervals are more complex, since we need to also re-estimate our IPTW to account for that variability. Below is code to estimate the corresponding confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% LCL: -0.08\n",
      "95% UCL: 0.115\n"
     ]
    }
   ],
   "source": [
    "# Step 1: divide data\n",
    "dfss = df.loc[df['S'] == 1].copy()\n",
    "dftp = df.loc[df['S'] == 0].copy()\n",
    "rd_bs = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Step 2: Resample data\n",
    "    dfs = dfss.sample(n=dfss.shape[0], replace=True)\n",
    "    dft = dftp.sample(n=dftp.shape[0], replace=True)\n",
    "\n",
    "    # Step 3: restack the data\n",
    "    dfb = pd.concat([dfs, dft])\n",
    "    \n",
    "    # Step 4: Estimate IPTW\n",
    "    iptw = IPTW(dfb, treatment='A', stabilized=True)\n",
    "    iptw.regression_models('L + W + W_sq', print_results=False)\n",
    "    iptw.fit()\n",
    "    dfb['iptw'] = iptw.Weight\n",
    "\n",
    "    # Step 5: Estimate IPSW\n",
    "    ipsw = IPSW(dfb, exposure='A', outcome='Y', selection='S', \n",
    "                generalize=True, weights='iptw')\n",
    "    ipsw.regression_models('L + W + L:W', print_results=False)\n",
    "    ipsw.fit()\n",
    "\n",
    "    rd_bs.append(ipsw.risk_difference)\n",
    "\n",
    "se = np.std(rd_bs, ddof=1)\n",
    "\n",
    "print('95% LCL:', np.round(rd - 1.96*se, 3))\n",
    "print('95% UCL:', np.round(rd + 1.96*se, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G-transport formula\n",
    "Implementation-wise, the g-transport formula remains the same. The only requirement is that we include all confounders for the A-Y relationship into the g-transport formula. This makes no difference in our example, because our modifiers of concern in the RCT are also the confounders in our observational study. The g-transport formula has the disadvantage of requiring that all confounders are measured in both the study sample and the target population sample. If all confounders are not measured in the target population sample, IPSW may be the only option to generalize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "                       g-Transport formula\n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.0567\n",
      "Risk Ratio:       1.1806\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "gtf = GTransportFormula(df, exposure='A', outcome='Y', selection='S', generalize=True)\n",
    "gtf.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "gtf.fit()\n",
    "gtf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented-IPSW\n",
    "Similar to `IPSW`, we need to calculate IPTW for the augmented-IPSW. Below is code to estimate `AIPSW` and the corresponding confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "           Augmented Inverse Probability of Sampling Weights          \n",
      "======================================================================\n",
      "Treatment:        A               Sample Observations:  486                 \n",
      "Outcome:          Y               Target Observations:  2514                \n",
      "Target estimate:  Generalize     \n",
      "----------------------------------------------------------------------\n",
      "Risk Difference:  0.0545\n",
      "Risk Ratio:       1.1722\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "aipw = AIPSW(df, exposure='A', outcome='Y', selection='S', \n",
    "             generalize=True, weights='iptw')\n",
    "aipw.weight_model('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "aipw.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "aipw.fit()\n",
    "aipw.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% LCL: -0.087\n",
      "95% UCL: 0.123\n"
     ]
    }
   ],
   "source": [
    "# Step 1: divide data\n",
    "dfss = df.loc[df['S'] == 1].copy()\n",
    "dftp = df.loc[df['S'] == 0].copy()\n",
    "rd_bs = []\n",
    "\n",
    "for i in range(200):\n",
    "    # Step 2: Resample data\n",
    "    dfs = dfss.sample(n=dfss.shape[0], replace=True)\n",
    "    dft = dftp.sample(n=dftp.shape[0], replace=True)\n",
    "\n",
    "    # Step 3: restack the data\n",
    "    dfb = pd.concat([dfs, dft])\n",
    "    \n",
    "    # Step 4: Estimate IPTW\n",
    "    iptw = IPTW(dfb, treatment='A', stabilized=True)\n",
    "    iptw.regression_models('L + W + W_sq', print_results=False)\n",
    "    iptw.fit()\n",
    "    dfb['iptw'] = iptw.Weight\n",
    "\n",
    "    # Step 5: Estimate IPSW\n",
    "    aipw = AIPSW(dfb, exposure='A', outcome='Y', selection='S', \n",
    "                 generalize=True, weights='iptw')\n",
    "    aipw.weight_model('L + W + W_sq + L:W + L:W_sq', print_results=False)\n",
    "    aipw.outcome_model('A + L + W + W_sq + A:L + A:W + A:W_sq', print_results=False)\n",
    "    aipw.fit()\n",
    "\n",
    "    rd_bs.append(aipw.risk_difference)\n",
    "\n",
    "se = np.std(rd_bs, ddof=1)\n",
    "\n",
    "print('95% LCL:', np.round(rd - 1.96*se, 3))\n",
    "print('95% UCL:', np.round(rd + 1.96*se, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this tutorial, I demonstrated three different estimators to generalize both randomized trial results and observational results to a target population. In the next tutorial, we will address the problem of transportability.\n",
    "\n",
    "## Further Readings\n",
    "Lesko CR, Buchanan AL, Westreich D, Edwards JK, Hudgens MG, & Cole SR. (2017). Generalizing study results: a potential outcomes perspective. Epidemiology (Cambridge, Mass.), 28(4), 553\n",
    "\n",
    "Dahabreh IJ, Hernan MA, Robertson SE, Buchanan A, Steingrimsson JA. (2019). Generalizing trial findings in nested trial designs with sub-sampling of non-randomized individuals. arXiv preprint arXiv:1902.06080"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
